{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up and package your code and results\n",
    "\n",
    "Exercise for applying some good (Python) practices to your code.\n",
    "\n",
    "* **Contact:** mate.balajti@unibas.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Testing and additional documentation\n",
    "\n",
    "Pointers for all exercises in this part are available in the Jupyter notebook\n",
    "`good_practices.ipynb`.\n",
    "\n",
    "Maintainable code includes documentation and testing. For each of these\n",
    "subtasks, **please do not forget to update dependencies (e.g., `flake8`,\n",
    "`pytest`).**\n",
    "\n",
    "> Note: Please use your code from Exercise 1, and write it into a separate python file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Add type hints to your code (1 point)\n",
    "\n",
    "Add type hints to your custom Python function/method signatures. It will be\n",
    "enough to only add type hints for all input arguments and the return values,\n",
    "although you are of course welcome to add them for any local variables as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(path: str) -> tuple[list[str], list[str]]:\n",
    "    headers = []\n",
    "    sequences = []\n",
    "    current_sequence = \"\"\n",
    "\n",
    "    with open(path, 'r') as fasta_file:\n",
    "        for line in fasta_file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if current_sequence:\n",
    "                    sequences.append(current_sequence)\n",
    "                    current_sequence = \"\"\n",
    "                headers.append(line[1:])\n",
    "            else:\n",
    "                current_sequence += line\n",
    "\n",
    "        if current_sequence:\n",
    "            sequences.append(current_sequence)\n",
    "\n",
    "\n",
    "    return headers, sequences\n",
    "\n",
    "def discard_ambiguous_seqs(header: list[str], sequence: list[str]) -> \\\n",
    "  tuple[: list[str], : list[str]]:\n",
    "\n",
    "    l1_header = []\n",
    "    l2_sequence = []\n",
    "    DNA_alphabet = {\"A\", \"G\", \"C\", \"T\"}\n",
    "\n",
    "    for n, seq in zip(header, sequence):\n",
    "\n",
    "        if all(char.upper() in DNA_alphabet for char in seq):\n",
    "            l1_header.append(n)\n",
    "            l2_sequence.append(seq)\n",
    "    \n",
    "\n",
    "    return l1_header, l2_sequence\n",
    "\n",
    "def nucleotide_frequencies(seqs: list[str]) -> None:\n",
    "    # count nucleotides\n",
    "    nucleotides_count = {'A' : 0, 'C' : 0, 'G' : 0, 'T' : 0}\n",
    "    total = 0\n",
    "\n",
    "    for seq in seqs:\n",
    "        for nucleotide in seq.upper():\n",
    "            if nucleotide in nucleotides_count:\n",
    "                nucleotides_count[nucleotide] += 1\n",
    "                total += 1\n",
    "\n",
    "    if total > 0:\n",
    "        for nucleotide in nucleotides_count:\n",
    "            frequency = nucleotides_count[nucleotide] / total\n",
    "            print(f\"{nucleotide} : {frequency: .2f}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No nucleotides\")\n",
    "\n",
    "\n",
    "def map_reads(filename1: str, filename2: str) -> dict[dict[str: list[int]]]:\n",
    "    query_headers, query_sequences = parse_fasta(filename1)\n",
    "    reference_headers, reference_sequences = parse_fasta(filename2)\n",
    "\n",
    "    query_headers, query_sequences = discard_ambiguous_seqs(query_headers, query_sequences)\n",
    "\n",
    "    print(\"Query nucleotides frequency:\")\n",
    "    nucleotide_frequencies(query_sequences)\n",
    "\n",
    "    print(\"Reference nucleotides frequency:\")\n",
    "    nucleotide_frequencies(reference_sequences)\n",
    "\n",
    "    results = {header: {} for header in query_headers}\n",
    "\n",
    "    for query_header, query_seq in zip (query_headers, query_sequences):\n",
    "        for ref_header, ref_seq in zip(reference_headers, reference_sequences):\n",
    "\n",
    "            start = 0\n",
    "            while True:\n",
    "                start = ref_seq.find(query_seq, start)\n",
    "                if start == -1:\n",
    "                    break\n",
    "                if ref_header not in results[query_header]:\n",
    "                    results[query_header][ref_header] = []\n",
    "                results[query_header][ref_header].append(start + 1)\n",
    "                start += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "filename1 = \"PiB_2024_Block_2_Exercise_1/sequences.fasta\"\n",
    "filename2 = \"PiB_2024_Block_2_Exercise_1/genome.fasta\"\n",
    "\n",
    "hits = map_reads(filename1, filename2)\n",
    "\n",
    "print(\"Hits :\")\n",
    "for query, refs in hits.items():\n",
    "    print(f\"{query}: {refs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Add docstrings to your code (1 point)\n",
    "\n",
    "Add Google-style docstrings to your custom Python functions/methods. Please do\n",
    "not include argument and return value types in the docstrings, as these have\n",
    "been already added to the signatures themselves (which is a much better idea,\n",
    "because the actual code is always the source of truth, and thus the risk of\n",
    "code and documentation diverging over time is reduced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(path: str) -> tuple[list[str], list[str]]:\n",
    "    \"\"\"\n",
    "    Read a FASTA file and extracts sequence headers and sequences.\n",
    "\n",
    "    Args:\n",
    "        path: Path to the FASTA file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple with two lists:\n",
    "        - headers: List of sequence headers.\n",
    "        - sequences: List of corresponding sequences.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    sequences = []\n",
    "    current_sequence = \"\"\n",
    "\n",
    "    with open(path, 'r') as fasta_file:\n",
    "        for line in fasta_file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if current_sequence:\n",
    "                    sequences.append(current_sequence)\n",
    "                    current_sequence = \"\"\n",
    "                headers.append(line[1:])\n",
    "            else:\n",
    "                current_sequence += line\n",
    "\n",
    "        if current_sequence:\n",
    "            sequences.append(current_sequence)\n",
    "\n",
    "    return headers, sequences\n",
    "\n",
    "\n",
    "def discard_ambiguous_seqs(\n",
    "    header: list[str], sequence: list[str]\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    \"\"\"\n",
    "    Removes sequences containing ambiguous characters from the input.\n",
    "\n",
    "    Args:\n",
    "        header: List of sequence headers.\n",
    "        sequence: List of nucleotide sequences.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - l1_header: Filtered list of sequence headers.\n",
    "        - l2_sequence: Filtered list of sequences without ambiguous characters.\n",
    "    \"\"\"\n",
    "    l1_header = []\n",
    "    l2_sequence = []\n",
    "    DNA_alphabet = {\"A\", \"G\", \"C\", \"T\"}\n",
    "\n",
    "    for n, seq in zip(header, sequence):\n",
    "        if all(char.upper() in DNA_alphabet for char in seq):\n",
    "            l1_header.append(n)\n",
    "            l2_sequence.append(seq)\n",
    "\n",
    "    return l1_header, l2_sequence\n",
    "\n",
    "\n",
    "def nucleotide_frequencies(seqs: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Calculates and prints the frequency of nucleotides in the input sequences.\n",
    "\n",
    "    Args:\n",
    "        seqs: List of nucleotide sequences.\n",
    "\n",
    "    Prints:\n",
    "        The relative frequency of each nucleotide (A, C, G, T) in the sequences.\n",
    "    \"\"\"\n",
    "    nucleotides_count = {'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
    "    total = 0\n",
    "\n",
    "    for seq in seqs:\n",
    "        for nucleotide in seq.upper():\n",
    "            if nucleotide in nucleotides_count:\n",
    "                nucleotides_count[nucleotide] += 1\n",
    "                total += 1\n",
    "\n",
    "    if total > 0:\n",
    "        for nucleotide in nucleotides_count:\n",
    "            frequency = nucleotides_count[nucleotide] / total\n",
    "            print(f\"{nucleotide} : {frequency: .2f}\")\n",
    "    else:\n",
    "        print(\"No nucleotides\")\n",
    "\n",
    "\n",
    "def map_reads(filename1: str, filename2: str) -> dict[str, dict[str, list[int]]]:\n",
    "    \"\"\"\n",
    "    Maps query sequences to reference sequences and finds matching positions.\n",
    "\n",
    "    Args:\n",
    "        filename1: Path to the query FASTA file.\n",
    "        filename2: Path to the reference FASTA file.\n",
    "\n",
    "    Returns:\n",
    "        A nested dictionary where:\n",
    "        - Keys are query sequence headers.\n",
    "        - Values are dictionaries where keys are reference sequence headers, and values are lists of starting positions where the query sequence matches the reference.\n",
    "    \"\"\"\n",
    "    query_headers, query_sequences = parse_fasta(filename1)\n",
    "    reference_headers, reference_sequences = parse_fasta(filename2)\n",
    "\n",
    "    query_headers, query_sequences = discard_ambiguous_seqs(query_headers, query_sequences)\n",
    "\n",
    "    print(\"Query nucleotides frequency:\")\n",
    "    nucleotide_frequencies(query_sequences)\n",
    "\n",
    "    print(\"Reference nucleotides frequency:\")\n",
    "    nucleotide_frequencies(reference_sequences)\n",
    "\n",
    "    results = {header: {} for header in query_headers}\n",
    "\n",
    "    for query_header, query_seq in zip(query_headers, query_sequences):\n",
    "        for ref_header, ref_seq in zip(reference_headers, reference_sequences):\n",
    "            start = 0\n",
    "            while True:\n",
    "                start = ref_seq.find(query_seq, start)\n",
    "                if start == -1:\n",
    "                    break\n",
    "                if ref_header not in results[query_header]:\n",
    "                    results[query_header][ref_header] = []\n",
    "                results[query_header][ref_header].append(start + 1)\n",
    "                start += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Main script\n",
    "filename1 = \"PiB_2024_Block_2_Exercise_1/sequences.fasta\"\n",
    "filename2 = \"PiB_2024_Block_2_Exercise_1/genome.fasta\"\n",
    "\n",
    "hits = map_reads(filename1, filename2)\n",
    "\n",
    "print(\"Hits:\")\n",
    "for query, refs in hits.items():\n",
    "    print(f\"{query}: {refs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Make sure your code lints (1 point)\n",
    "\n",
    "Please use the `flake8` linter to help you refactor your code such that it\n",
    "adheres to Python conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flake8 in c:\\users\\nicol\\anaconda3\\lib\\site-packages (7.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in c:\\users\\nicol\\anaconda3\\lib\\site-packages (from flake8) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in c:\\users\\nicol\\anaconda3\\lib\\site-packages (from flake8) (2.11.1)\n",
      "Requirement already satisfied: pyflakes<3.3.0,>=3.2.0 in c:\\users\\nicol\\anaconda3\\lib\\site-packages (from flake8) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install flake8"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "flake8 cd /mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational\\ science/Prog\\ in\\ Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py\n",
    "\n",
    "\n",
    "What it showed:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:32:80: E501 line too long (84 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:33:80: E501 line too long (80 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:34:80: E501 line too long (85 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:38:80: E501 line too long (81 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:40:80: E501 line too long (85 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:41:80: E501 line too long (85 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:42:80: E501 line too long (83 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:44:80: E501 line too long (84 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:83:80: E501 line too long (135 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:84:80: E501 line too long (120 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:100:80: E501 line too long (81 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:123:80: E501 line too long (84 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:124:80: E501 line too long (82 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:125:80: E501 line too long (84 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:137:80: E501 line too long (84 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:138:80: E501 line too long (82 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:140:80: E501 line too long (85 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:141:80: E501 line too long (86 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:179:80: E501 line too long (86 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:180:80: E501 line too long (89 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:187:80: E501 line too long (80 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:188:80: E501 line too long (87 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:189:80: E501 line too long (84 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:192:80: E501 line too long (85 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:193:80: E501 line too long (88 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:194:80: E501 line too long (87 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:247:80: E501 line too long (81 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:283:80: E501 line too long (85 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:287:80: E501 line too long (100 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:297:80: E501 line too long (81 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:298:80: E501 line too long (88 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:334:80: E501 line too long (152 > 79 characters)\n",
    "/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/Exercise_1.py:346:23: F821 undefined name 'null'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Test your code (2 points)\n",
    "\n",
    "Write unit tests for all of your custom Python functions/methods, run tests\n",
    "with `pytest` and make sure all tests pass. Compute the code `coverage` and\n",
    "make sure it's at a 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytest  /mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational\\ science/Pr\n",
    "og\\ in\\ Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_1/test_exercise_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 2: Package and version control your code\n",
    "\n",
    "### Reorganize your files\n",
    "\n",
    "Please create an empty directory with the following files and directories:\n",
    "\n",
    "* `README.md`: A [markdown](https://github.github.com/gfm/)-formatted file\n",
    "  containing instructions on how to deploy (e.g., set up a Conda environment\n",
    "  or build a Docker image; see below) and run your code and answering all\n",
    "  questions from previous exercises.\n",
    "* `src/`: A directory containing all your custom code (except for tests).\n",
    "* `tests/`: A directory that will contain test code (see next exercise). You\n",
    "  can also put all your test/input files in this directory, ideally in a\n",
    "  subdirectoy (e.g., `test_files/`).\n",
    "* `run_me.sh`: A single Bash script running all code from all exercises on\n",
    "  the test input files as per the previous two exercises. Please also include\n",
    "  the calls to run `flake8` and `pytest` on your core repository after you have\n",
    "  implemented these. This is really a poor man's workflow, but it's still a lot\n",
    "  better than having to guess how you ran your code. If you like, you can\n",
    "  organize this file so that it executes other Bash scripts (in `src/`) to keep\n",
    "  it more tidy.\n",
    "* [OPTIONAL] `LICENSE`: A file containing an\n",
    "  [Open Source License](https://opensource.org/licenses), such as the\n",
    "  [MIT](https://opensource.org/licenses/MIT) or\n",
    "  [Apache 2.0](https://opensource.org/licenses/Apache-2.0) license; you can use\n",
    "  [this service](https://choosealicense.com/) to pick a license you like.\n",
    "* [OPTIONAL] `environment.yml` OR `Dockerfile`: A [Conda enviroment\n",
    "  file](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#sharing-an-environment)\n",
    "  listing all your Python and third-party requirements. Alternatively, a\n",
    "  `Dockerfile` that can be used to build an image that contains all\n",
    "  dependencies.\n",
    "* [OPTIONAL] `.gitignore`: A file with patterns indicating files/artefacts that Git should\n",
    "  not version control, e.g., test reports. Generate it from\n",
    "  <https://gitignore.io> for Python and your code editor.\n",
    "\n",
    "### Create a Git repository and push to a remote\n",
    "\n",
    "* Please create a Git repository based off your new directory.\n",
    "* Stage and commit all contents of the directory, with e.g. the message \"initial commit\".\n",
    "* Create a blank/empty project on [GitHub](https://github.com/) or\n",
    "  [GitLab](https://gitlab.com/).\n",
    "* Add the remote URL of your GitHub/Lab project to your local Git repository\n",
    "  and push your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Use a workflow language/engine to run your analysis \n",
    "\n",
    "As mentioned above, specifiying a Bash file to run your analysis is not very\n",
    "good. It will be difficult to parallelize your code, scatter/gather multiple\n",
    "jobs of the same task, keep sufficient logging and provenance information, and\n",
    "it will be difficult to share your analysis in a way that it is easily\n",
    "reproducible/reusable. Workflow languages and corresponding management\n",
    "systems/engines take care of all of these things and more.\n",
    "\n",
    "If you are (planning on) doing bioinformatics analyses more regularly, we\n",
    "strongly recommend you to pick up one of these languages, e.g.,\n",
    "[Nextflow](https://www.nextflow.io/) (Groovy-based) or\n",
    "[Snakemake](https://snakemake.readthedocs.io/en/stable/) (Python-based) are two\n",
    "popular choices that we frequently use in our lab.\n",
    "\n",
    "If you are interested, you can follow a tutorial on either of these domain-\n",
    "specific languages and learn how you can package your code as a proper\n",
    "shareable workflow.\n",
    "\n",
    "> Note: Please use your code from Exercise 2, organize them into 2 Nextflow processes and copy the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "// Define the parameters for input files\n",
    "params.genomeFasta = \"/data/Mus_musculus.GRCm38.dna_rm.chr19.fa\"\n",
    "params.gtfFile = \"/data/Mus_musculus.GRCm38.88.chr19.gtf\"\n",
    "params.reads1 = \"/data/control.mate_1.fq\"\n",
    "params.reads2 = \"/data/control.mate_2.fq\"\n",
    "params.outputDir = \"/data/output_files\"\n",
    "\n",
    "// Process that generates our Genome Index\n",
    "\n",
    "process generateGenomeIndex {\n",
    "    tag \"generate genome index\"\n",
    "    \n",
    "    input:\n",
    "    path genomeFasta, gtfFile\n",
    "\n",
    "    output:\n",
    "    path \"${params.outputDir}/STAR_index\"\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    STAR --runMode genomeGenerate \\\n",
    "         --genomeDir ${params.outputDir}/STAR_index \\\n",
    "         --genomeFastaFiles ${genomeFasta} \\\n",
    "         --sjdbGTFfile ${gtfFile} \\\n",
    "         --runThreadN 4\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "// Process that aligns our Reads and gives the alignment with all the informations\n",
    "\n",
    "process alignReads {\n",
    "    tag \"align reads\"\n",
    "\n",
    "    input:\n",
    "    path genomeDir, reads1, reads2\n",
    "\n",
    "    output:\n",
    "    path \"${params.outputDir}/control_alignment_Aligned.out.sam\"\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    STAR --runMode alignReads \\\n",
    "         --genomeDir ${genomeDir} \\\n",
    "         --readFilesIn ${reads1} ${reads2} \\\n",
    "         --runThreadN 4 \\\n",
    "         --outFileNamePrefix ${params.outputDir}/control_alignment_\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "workflow {\n",
    "    genomeIndexDir = generateGenomeIndex(params.genomeFasta, params.gtfFile)\n",
    "    alignReads(genomeIndexDir, params.reads1, params.reads2)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
