{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning reads & processing SAM files\n",
    "\n",
    "Exercise for creating and processing short read alignments.\n",
    "\n",
    "* **Contact:** mate.balajti@unibas.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "\n",
    "Be sure to nicely format your answer.\n",
    "Indicate your name in the file name!\n",
    "_Ex2_solutions_Name_LastName.py_ would be a good approach to this.\n",
    "Document, report and detail your work, make sure we can follow and execute it.\n",
    "If we cannot understand the chaos in your answers, it won't be considered for grading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Operating system\n",
    "\n",
    "For solving these exercises, you need to work in Bash on a Unix-type terminal,\n",
    "so if you are behind either a Linux distribution, a Mac or a BSD system etc.,\n",
    "you ​ should ​ be good to go. If instead you only have access to a Windows 10/11\n",
    "computer, you should be able to make use of the support the system offers for\n",
    "Linux/Ubuntu through their cooperation with Canonical. For older Windows\n",
    "versions or even better compatibility, you can also always run a virtual\n",
    "machine with any Linux distribution you like.\n",
    "\n",
    "See\n",
    "[here](https://www.hpe.com/us/en/insights/articles/3-good-ways-to-run-linux-on-windows-2007.html​)\n",
    "for some pointers for either approach.\n",
    "\n",
    "Finally, if you have experience with Docker, one other possible option is to\n",
    "use a Docker image that contains all required software. For example, starting\n",
    "from a Linux image (e.g., latest Ubuntu), which provides Linux/GNU/Bash out of\n",
    "the box, you could install STAR and/or any other required Linux software by\n",
    "writing an appropriate Dockerfile and then building that image. You can also\n",
    "search online for available images that already contain these tools (e.g.,\n",
    "[this](https://hub.docker.com/r/mgibio/star/dockerfile​) looks like one you\n",
    "could use for running STAR; see below). If you decide to go this route, be\n",
    "aware that Docker on Windows still runs in a VM and support is not always\n",
    "stable.\n",
    "\n",
    "> **Note:** If you are planning to do more bioinformatics work in the future,\n",
    "> it is definitely a good idea to have a stable Linux system at hand at all\n",
    "> times. In this case, you might want to consider installing a Linux\n",
    "> distribution side-by-side with your Windows OS (search for “Linux Windows\n",
    "> dual boot” or similar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software\n",
    "\n",
    "In the last exercise, you were asked to write a simple, naive short read\n",
    "aligner from scratch. While this is a good exercise, it is not suitable for\n",
    "actual analysis, because your code won’t be optimized to handle the amounts of\n",
    "data that next-generation sequencing typically yields. Since the dawn of\n",
    "high-throughput sequencing techniques in the mid 2000’s, a lot of effort has\n",
    "been put into designing and implementing very efficient methods at mapping\n",
    "short reads to reference sequences. For this exercise, we will use a popular\n",
    "option called [STAR](https://github.com/alexdobin/STAR). Among many other\n",
    "features, STAR supports spliced alignments and optionally accepts gene\n",
    "annotations in GTF format next to a genome reference to increase the fidelity\n",
    "of mapping reads that cover splice junctions (if not provided, STAR, by\n",
    "default, will try to infer splice junctions from the genome reference and the\n",
    "reads). Please either install STAR (and any other third-party software you\n",
    "need) via the [Conda](https://docs.conda.io/en/latest/miniconda.html) package\n",
    "manager _OR_ use Docker containers as suggested above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation for Windows\n",
    "\n",
    "_STAR_ is only available as Docker image on Windows.\n",
    "Here we assume Docker is not yet installed and Windows 10 or 11 is used.\n",
    "Coarse installation steps:\n",
    "* Install WSL2 (Windows subsystem for Linux) backend\n",
    "  https://learn.microsoft.com/en-us/windows/wsl/install\n",
    "* Install Docker https://docs.docker.com/desktop/install/windows-install/\n",
    "* Ensure the installation was successful by following the _Quick Start Guide_.\n",
    "* Get the STAR docker image by executing the following command in\n",
    "a PowerShell or Windows Command Prompt window (in Linux it is called a terminal window).\n",
    "  ```bash\n",
    "  docker pull mgibio/star\n",
    "  ```\n",
    "\n",
    "> Note: please refer to the most up-to-date documentation\n",
    "> by checking the online instructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a Docker image\n",
    "\n",
    "To have the local files visible in the container, one needs to mount the directory onto the host (in this case the STAR container). \n",
    "\n",
    "For example, to mount `C:\\paths\\to\\test_files` (absolute path to directory `test_files`) onto `/docker_main/files` (the path and name of the directory on the Linux-based host):\n",
    "```bash\n",
    "docker run -it \\\n",
    "  --mount type=bind,source=\"C:\\paths\\to\\test_files\",target=/docker_main/files \\\n",
    "  mgibio/star:latest\n",
    "```\n",
    "\n",
    "> Note: on Linux, paths are constructed with slash \"/\", whereas on Windows with backslash \"\\\\\"!\n",
    "\n",
    "> Note: to get help about the command `docker run`,\n",
    "> try running `docker run --help`\n",
    "> or search online for the command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Create index (2 points)\n",
    "\n",
    "Follow STAR’s manual to create an index of the provided genome ​`FASTA`​ file\n",
    "and ​`GTF`​ gene annotations. Note that to allow the mapping to be done on a\n",
    "laptop, only chromosome 19 and the corresponding gene annotations are provided.\n",
    "In a typical setting, indexing and mapping would be done on all chromosomes and\n",
    "an unfiltered set of annotations. Note also that files are provided in a\n",
    "compressed form (`GZIP`) for easy sharing and may need to be uncompressed\n",
    "before use (check the instructions whether passing `GZIP`ped files directly is\n",
    "accepted).\n",
    "\n",
    "Required files:\n",
    "\n",
    "* Genome:​ `Mus_musculus.GRCm38.dna_rm.chr19.fa.gz`\n",
    "* Gene annotations: `Mus_musculus.GRCm38.88.chr19.gtf.gz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gunzip Mus_musculus.GRCm38.dna_rm.chr19.fa.gz \n",
    "# gunzip Mus_musculus.GRCm38.88.chr19.gtf.gz\n",
    "# Uncompress the files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) docker run -it --rm \\\n",
    "    --mount type=bind,source=\"/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in                  Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_2\",target=/data \\\n",
    "  mgibio/star \\\n",
    "  bash -c \"mkdir -p /data/output_files\" \n",
    "\n",
    "2)  docker run -it --rm \\\n",
    "  --mount type=bind,source=\"/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_2\",target=/data \\\n",
    "  mgibio/star \\\n",
    "  STAR --runMode genomeGenerate \\\n",
    "  --genomeDir /data/output_files \\\n",
    "  --genomeFastaFiles /data/Mus_musculus.GRCm38.dna_rm.chr19.fa \\\n",
    "  --sjdbGTFfile /data/Mus_musculus.GRCm38.88.chr19.gtf \\\n",
    "  --runThreadN 4\n",
    "\n",
    "\n",
    "1) Create the directory for the output files\n",
    "2) Create index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2: Align reads (2 points)\n",
    "\n",
    "Follow STAR’s manual to align reads to the reference, using the index you have\n",
    "created in exercise 2.1. Note that we are dealing here with (part of) a\n",
    "paired-end sequencing library, so you will need to provide both read library\n",
    "files for this step.\n",
    "\n",
    "ATTENTION: The running of the mapping may take quite some time if you're working on your local machine. (up to 10-15min)\n",
    "\n",
    "Required files:\n",
    "\n",
    "* Control mate 1: `control.mate_1.fq.gz`\n",
    "* Control mate 2: `control.mate_2.fq.gz`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) gunzip control.mate_1.fq.gz\n",
    "gunzip control.mate_2.fq.gz\n",
    "\n",
    "\n",
    "2) docker run -it --rm \\\n",
    "  --mount type=bind,source=\"/mnt/c/Users/nicol/OneDrive/Desktop/UniBasel/Computational science/Prog in Bioinfo/Zavolan/PiB_2024_Block_2_Exercise_2\",target=/data \\\n",
    "  mgibio/star \\\n",
    "  STAR --runMode alignReads \\\n",
    "  --genomeDir /data/output_files \\\n",
    "  --readFilesIn /data/control.mate_1.fq /data/control.mate_2.fq \\\n",
    "  --runThreadN 4 \\\n",
    "  --outFileNamePrefix /data/output_files/control_alignment_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Process alignments\n",
    "\n",
    "#### Exercise 2.3: Count reads (3 points)\n",
    "\n",
    "Find out from the STAR output (log or `SAM` files): (see file `bash_basics.sh` for help)\n",
    "\n",
    "* How many alignments were reported?\n",
    "* How many reads were uniquely mapped?  \n",
    "  **Hint:** check for the `NH` (number of hits) SAM tag\n",
    "* How many reads were mapped to multiple loci?\n",
    "* How many reads could not be mapped?\n",
    "\n",
    "Compare the sum of uniquely mapped, multi-mapped and unmapped reads to the\n",
    "total number of reads in the ​ FASTQ​ input files. Do the numbers match?\n",
    "\n",
    "> **Note:** See the [SAM​\n",
    "> specification](https://samtools.github.io/hts-specs/SAMv1.pdf) for more info\n",
    "> on SAM files."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) 445798\n",
    "2) 393775\n",
    "3) 3913\n",
    "4) 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.4: Run custom functions on STAR results (3 points)\n",
    "\n",
    "`FASTQ`​ (for reads), ​`FASTA`​ (for reference sequences and reads if sequencing\n",
    "quality scores are disregarded or discarded), ​`GTF`​/`GFF`​ (for gene\n",
    "annotations/features), `SAM` (for alignments; with the corresponding\n",
    "binary/compressed versions ​`BAM`,​ and, more recently, ​`CRAM​`), ​`BED​` (generic\n",
    "tabular format for representing genomic ranges) are the main file types that\n",
    "are used in the analysis of RNA-Seq data. Relevant tools in the field will\n",
    "nowadays almost always require input files and report their own outputs in any\n",
    "of these formats. However, not every tool accepting a `FASTA`​ file as input\n",
    "will also accept a ​`FASTQ`​ file, although it is trivial to convert ​`FASTQ​` to\n",
    "`FASTA` in a non-lossy way. In addition, both for legacy and new tools, custom\n",
    "formats are still being used, occasionally, to represent specialized\n",
    "information. Therefore, writing and applying parsers and converters to convert\n",
    "outputs of one tool such that they can be used as inputs to another is a\n",
    "somewhat menial, but common task that bioinformaticians are often faced with.\n",
    "\n",
    "To practice this and connect to the work you have done in the previous exercise:\n",
    "\n",
    "* Write code that converts a ​`SAM​` file to a ​`FASTA`​ file and apply it on the\n",
    "  output of exercise 2.2 (align reads). If you didn’t manage to solve exercise 2.3, write\n",
    "  code that converts ​`FASTQ`​ to ​`FASTA` instead.\n",
    "* Convert your files to ​`FASTA`​ and then apply your functions from the previous\n",
    "  session to the output.\n",
    "  * Note: `map_reads()` will likely not finish in reasonable time.\n",
    "    Thus, it is fine to stop it. But report and reason about why this could be the case. What makes the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasta file 'reads.fasta' created.\n"
     ]
    }
   ],
   "source": [
    "def sam_to_fasta(sam_file, fasta_file):\n",
    "    with open(sam_file, 'r') as sam, open(fasta_file, 'w') as fasta:\n",
    "        for line in sam:\n",
    "            if line.startswith('@'):\n",
    "                continue\n",
    "            parts = line.strip().split('\\t')\n",
    "            read_name = parts[0]\n",
    "            sequence = parts[9]\n",
    "\n",
    "            fasta.write(f\">{read_name}\\n{sequence}\\n\")\n",
    "    print(f\"Fasta file '{fasta_file}' created.\")\n",
    "\n",
    "\n",
    "sam_file = \"output_files/control_alignment_Aligned.out.sam\"\n",
    "fasta_file = \"reads.fasta\"\n",
    "sam_to_fasta(sam_file, fasta_file)\n",
    "\n",
    "\n",
    "# It gives me FileNotFoundError, but the file is present and the name is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Differential gene expression analysis (optional)\n",
    "\n",
    "One of the most common experiment types making use of RNA-Seq is a differential\n",
    "gene expression analysis where gene expression levels across different\n",
    "conditions (e.g., healthy vs disease) or compared to each other. This type of\n",
    "experiment is often the basis for discovering genes that are relevant to a\n",
    "given physiological or disease process. Following this relatively open-ended\n",
    "discovery phase of a study, a list of genes with a strikingly different\n",
    "expression pattern is often the basis for further, more detailed mechanistic\n",
    "studies.  While performing an entire differential gene expression analysis is\n",
    "beyond the scope of this limited seminar, you are invited to dig further into\n",
    "this topic in an open-ended way, by reading on the following topics and either\n",
    "writing your own code or apply available tools/packages for these tasks:\n",
    "\n",
    "Useful files:\n",
    "\n",
    "* Control mate 1: `control.mate_1.fq.gz`\n",
    "* Control mate 2: `control.mate_2.fq.gz`\n",
    "* Treated mate 1: `treated.mate_1.fq.gz`\n",
    "* Treated mate 2: `treated.mate_2.fq.gz`\n",
    "\n",
    "Procedure:\n",
    "\n",
    "* Create a table of counts for each gene (rows) and sample (columns)  \n",
    "  **Hint:** You can easily implement this yourself, but you can also make use\n",
    "  of the [HTSeq](https://htseq.readthedocs.io/en/release_0.11.1/count.html)\n",
    "  package for this task (can also be used to report counts for other features)\n",
    "* Analyze gene expression across different conditions based on such a count\n",
    "  table  \n",
    "  **Hint:** You can do this, e.g., with the\n",
    "  [edgeR](https://www.bioconductor.org/packages/release/bioc/html/edgeR.html)\n",
    "  package, written in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are doing any work in this regard, feel free to send it to the teaching assistant(s) for some feedback.\n",
    "\n",
    "> **Note:** As an alternative to alignment- and count-based approaches to a\n",
    "> differential gene expression, nowadays probabilistic methods are increasingly\n",
    "> being used for similar purposes.  These have several advantages, such as\n",
    "> (typically) requiring fewer steps and less compute resources. Importantly,\n",
    "> they provide abundances for individual transcripts and thus enable analyses,\n",
    "> such as differential transcript expression and isoform usage analysis, which\n",
    "> the count-based methods do not readily allow. A downside for these methods is\n",
    "> that they are not easy to understand in detail, making results harder to\n",
    "> interpret and potentially more sensitive to biases. The two main tools for\n",
    "> alignment-free estimation of transcript abundances are\n",
    "> [Salmon](​https://github.com/COMBINE-lab/salmon) and\n",
    "> [kallisto](https://github.com/pachterlab/kallisto​)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
